---
# The directory to store the K8s certificates and other configuration
k8s_conf_dir: "/var/lib/kubernetes"

harden_linux_ntp: "systemd-timesyncd"

# Password for user "root" and "k8s" is "k8s" in both cases
harden_linux_root_password: "$6$Ut6mSjl/MY.VCMqF$dJwSnGD8JfcqYQDZo6Coe8zzvyaz9jyPBuVI.F3PPGNGawvZESirv6kSXIaUFerB8HtLrra3nsPdCIN7DUkJ2/"
harden_linux_deploy_user: "k8s"
harden_linux_deploy_user_password: "$6$Ut6mSjl/MY.VCMqF$dJwSnGD8JfcqYQDZo6Coe8zzvyaz9jyPBuVI.F3PPGNGawvZESirv6kSXIaUFerB8HtLrra3nsPdCIN7DUkJ2/"
harden_linux_deploy_user_home: "/home/k8s"

harden_linux_sysctl_settings_user:
  "net.ipv4.ip_forward": 1
  "net.ipv6.conf.default.forwarding": 1
  "net.ipv6.conf.all.forwarding": 1

harden_linux_sshd_settings_user:
  "^Port ": "Port 22"
  "^PasswordAuthentication": "PasswordAuthentication yes"
  "^PermitRootLogin": "PermitRootLogin yes"

harden_linux_ufw_rules:
  - rule: "allow"
    to_port: "22"
    protocol: "tcp"
  - rule: "allow"
    to_port: "51820"
    protocol: "udp"
  - rule: "allow"
    to_port: "80"
    protocol: "tcp"
  - rule: "allow"
    to_port: "443"
    protocol: "tcp"
  - rule: "allow"
    to_port: "25"
    protocol: "tcp"

harden_linux_ufw_allow_networks:
  - "10.0.0.0/8"
  - "172.16.0.0/12"
  - "192.168.0.0/16"

harden_linux_ufw_logging: 'on'

harden_linux_ufw_defaults_user:
  "^DEFAULT_FORWARD_POLICY": 'DEFAULT_FORWARD_POLICY="ACCEPT"'

harden_linux_sshguard_whitelist:
  - "127.0.0.0/8"
  - "::1/128"
  - "10.0.0.0/8"

etcd_ca_conf_directory: "/tmp/k8s"
etcd_conf_dir: "/etc/etcd"
etcd_settings_user:
  "heartbeat-interval": "250"
  "election-timeout": "2500"
etcd_cert_hosts:
  - localhost
  - 127.0.0.1
  - 10.32.0.1
  - kubernetes
  - kubernetes.default
  - kubernetes.default.svc
  - kubernetes.default.svc.cluster
  - kubernetes.svc.cluster.local
  - 192.168.10.5
  - 192.168.10.10
  - 192.168.10.20
  - 192.168.10.30
  - 192.168.10.100
  - 192.168.10.110
  - 192.168.10.120
  - 192.168.10.130
  - 10.10.10.5
  - 10.10.10.10
  - 10.10.10.20
  - 10.10.10.30
  - 10.10.10.100
  - 10.10.10.110
  - 10.10.10.120
  - 10.10.10.130
  - test-controller1
  - test-controller2
  - test-controller3
  - test-worker1
  - test-worker2
  - test-worker3

k8s_ca_conf_directory_perm: "0775"
k8s_ca_file_perm: "0666"
k8s_ca_certificate_owner: "{{ k8s_config_owner }}"
k8s_ca_certificate_group: "{{ k8s_config_group }}"

k8s_config_cluster_name: "k8s"
k8s_config_directory_perm: "0777"
k8s_config_file_perm: "0666"
k8s_config_owner: "root"
k8s_config_group: "root"

k8s_encryption_config_directory: "{{k8s_config_directory}}"
k8s_encryption_config_key: "Y29uZmlndXJhdGlvbjIyCg=="
k8s_encryption_config_owner: "{{ k8s_config_owner }}"
k8s_encryption_config_group: "{{ k8s_config_owner }}"
k8s_encryption_config_directory_perm: "{{ k8s_config_directory_perm }}"
k8s_encryption_config_file_perm: "{{ k8s_config_file_perm }}"

k8s_worker_kubelet_conf_dir: "/var/lib/kubelet"

k8s_apiserver_secure_port: "6443"

k8s_apiserver_settings_user:
  "enable-aggregator-routing": "true"

k8s_worker_kubelet_settings:
  "config": "{{k8s_worker_kubelet_conf_dir}}/kubelet-config.yaml"
  "node-ip": "{{hostvars[inventory_hostname]['ansible_' + k8s_interface].ipv4.address}}"
  "container-runtime-endpoint": "unix:///run/containerd/containerd.sock"
  "kubeconfig": "{{k8s_worker_kubelet_conf_dir}}/kubeconfig"
  "seccomp-default": ""

containerd_flavor: "k8s"
containerd_tmp_directory: "/tmp"
containerd_runc_binary_directory: "/usr/local/sbin"
containerd_crictl_config_file: "crictl.yaml"
containerd_crictl_config_directory: "/etc"
containerd_cni_binary_directory: "/opt/cni/bin"

cilium_etcd_enabled: "false"
cilium_delegate_to: "test-assets"
cilium_helm_show_commands: true
cilium_etcd_interface: "{{ k8s_interface }}"

ca_etcd_csr_cn: "etcd"
ca_k8s_apiserver_csr_cn: "kubernetes"
etcd_server_csr_cn: "etcd"
etcd_peer_csr_cn: "etcd"
etcd_client_csr_cn_prefix: "etcd"
k8s_apiserver_csr_cn: "kubernetes"
k8s_admin_csr_cn: "admin"
k8s_controller_manager_sa_csr_cn: "service-accounts"


# The directory to store the K8s binaries
k8s_bin_dir: "/usr/local/bin"

# K8s release
k8s_release: "1.27.5"

# The interface on which the K8s services should listen on. As all cluster
# communication should use a VPN interface the interface name is
# normally "wg0" (WireGuard),"peervpn0" (PeerVPN) or "tap0".
k8s_interface: "tap0"

# The directory from where to copy the K8s certificates. By default this
# will expand to user's LOCAL $HOME (the user that run's "ansible-playbook ..."
# plus "/k8s/certs". That means if the user's $HOME directory is e.g.
# "/home/da_user" then "k8s_ca_conf_directory" will have a value of
# "/home/da_user/k8s/certs".
k8s_ca_conf_directory: "{{ '~/k8s/certs' | expanduser }}"

# Directory where kubeconfig for Kubernetes worker nodes and kube-proxy
# is stored among other configuration files. Same variable expansion
# rule applies as with "k8s_ca_conf_directory"
k8s_config_directory: "{{ '~/k8s/configs' | expanduser }}"

# K8s control plane binaries to download
k8s_controller_binaries:
  - kube-apiserver
  - kube-controller-manager
  - kube-scheduler
  - kubectl

# K8s kube-(apiserver|controller-manager-sa) certificates
k8s_certificates:
  - ca-k8s-apiserver.pem
  - ca-k8s-apiserver-key.pem
  - cert-k8s-apiserver.pem
  - cert-k8s-apiserver-key.pem
  - cert-k8s-controller-manager-sa.pem
  - cert-k8s-controller-manager-sa-key.pem

# K8s API daemon settings (can be overridden or additional added by defining
# "k8s_apiserver_settings_user")
k8s_apiserver_settings:
  "advertise-address": "{{ hostvars[inventory_hostname]['ansible_' + k8s_interface].ipv4.address }}"
  "bind-address": "{{ hostvars[inventory_hostname]['ansible_' + k8s_interface].ipv4.address }}"
  "secure-port": "6443"
  "enable-admission-plugins": "NodeRestriction,NamespaceLifecycle,LimitRanger,ServiceAccount,TaintNodesByCondition,Priority,DefaultTolerationSeconds,DefaultStorageClass,PersistentVolumeClaimResize,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota"
  "allow-privileged": "true"
  "authorization-mode": "Node,RBAC"
  "audit-log-maxage": "30"
  "audit-log-maxbackup": "3"
  "audit-log-maxsize": "100"
  "audit-log-path": "/var/log/audit.log"
  "event-ttl": "1h"
  "kubelet-preferred-address-types": "InternalIP,Hostname,ExternalIP"  # "--kubelet-preferred-address-types" defaults to:
                                                                       # "Hostname,InternalDNS,InternalIP,ExternalDNS,ExternalIP"
                                                                       # Needs to be changed to make "kubectl logs" and "kubectl exec" work.
  "runtime-config": "api/all=true"
  "service-cluster-ip-range": "10.32.0.0/16"
  "service-node-port-range": "30000-32767"
  "client-ca-file": "{{ k8s_conf_dir }}/ca-k8s-apiserver.pem"
  "etcd-cafile": "{{ k8s_conf_dir }}/ca-etcd.pem"
  "etcd-certfile": "{{ k8s_conf_dir }}/cert-k8s-apiserver-etcd.pem"
  "etcd-keyfile": "{{ k8s_conf_dir }}/cert-k8s-apiserver-etcd-key.pem"
  "encryption-provider-config": "{{ k8s_conf_dir }}/encryption-config.yaml"
  "kubelet-certificate-authority": "{{ k8s_conf_dir }}/ca-k8s-apiserver.pem"
  "kubelet-client-certificate": "{{ k8s_conf_dir }}/cert-k8s-apiserver.pem"
  "kubelet-client-key": "{{ k8s_conf_dir }}/cert-k8s-apiserver-key.pem"
  "service-account-key-file": "{{ k8s_conf_dir }}/cert-k8s-controller-manager-sa.pem"
  "service-account-signing-key-file": "{{ k8s_conf_dir }}/cert-k8s-controller-manager-sa-key.pem"
  "service-account-issuer": "https://{{ groups.k8s_controller | first }}:6443"
  "tls-cert-file": "{{ k8s_conf_dir }}/cert-k8s-apiserver.pem"
  "tls-private-key-file": "{{ k8s_conf_dir }}/cert-k8s-apiserver-key.pem"

# The directory to store controller manager configuration.
k8s_controller_manager_conf_dir: "/var/lib/kube-controller-manager"

# K8s controller manager settings (can be overridden or additional added by defining
# "k8s_controller_manager_settings_user")
k8s_controller_manager_settings:
  "bind-address": "{{ hostvars[inventory_hostname]['ansible_' + k8s_interface].ipv4.address }}"
  "secure-port": "10257"
  "cluster-cidr": "10.200.0.0/16"
  "allocate-node-cidrs": "true"
  "cluster-name": "kubernetes"
  "authentication-kubeconfig": "{{ k8s_controller_manager_conf_dir }}/kube-controller-manager.kubeconfig"
  "authorization-kubeconfig": "{{ k8s_controller_manager_conf_dir }}/kube-controller-manager.kubeconfig"
  "kubeconfig": "{{ k8s_controller_manager_conf_dir }}/kube-controller-manager.kubeconfig"
  "leader-elect": "true"
  "service-cluster-ip-range": "10.32.0.0/16"
  "cluster-signing-cert-file": "{{ k8s_conf_dir }}/cert-k8s-apiserver.pem"
  "cluster-signing-key-file": "{{ k8s_conf_dir }}/cert-k8s-apiserver-key.pem"
  "root-ca-file": "{{ k8s_conf_dir }}/ca-k8s-apiserver.pem"
  "requestheader-client-ca-file": "{{ k8s_conf_dir }}/ca-k8s-apiserver.pem"
  "service-account-private-key-file": "{{ k8s_conf_dir }}/cert-k8s-controller-manager-sa-key.pem"
  "use-service-account-credentials": "true"

# The directory to store scheduler configuration.
k8s_scheduler_conf_dir: "/var/lib/kube-scheduler"

# kube-scheduler settings
k8s_scheduler_settings:
  "bind-address": "{{ hostvars[inventory_hostname]['ansible_' + k8s_interface].ipv4.address }}"
  "config": "{{ k8s_scheduler_conf_dir }}/kube-scheduler.yaml"
  "authentication-kubeconfig": "{{ k8s_scheduler_conf_dir }}/kube-scheduler.kubeconfig"
  "authorization-kubeconfig": "{{ k8s_scheduler_conf_dir }}/kube-scheduler.kubeconfig"
  "requestheader-client-ca-file": "{{ k8s_conf_dir }}/ca-k8s-apiserver.pem"

# By default all tasks that needs to communicate with the Kubernetes
# cluster are executed on local host (127.0.0.1). But if that one
# doesn't have direct connection to the K8s cluster or should be executed
# elsewhere this variable can be changed accordingly.
k8s_controller_delegate_to: 127.0.0.1

# The port the control plane components should connect to etcd cluster
etcd_client_port: "2379"

# The interface the etcd cluster is listening on
etcd_interface: "tap0"

# The etcd certificates needed for the control plane components to be able
# to connect to the etcd cluster.
etcd_certificates:
  - ca-etcd.pem
  - ca-etcd-key.pem
  - cert-k8s-apiserver-etcd.pem
  - cert-k8s-apiserver-etcd-key.pem
